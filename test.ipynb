{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbcca9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing_extensions import Annotated, TypedDict\n",
    "from langchain_groq import ChatGroq, chat_models\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14d965b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a technical documentation assistant.\n",
    "\n",
    "You MUST output Markdown that conforms exactly to the following rules.\n",
    "This output will be parsed by a strict Markdown-to-Notion converter.\n",
    "\n",
    "ALLOWED BLOCK SYNTAX:\n",
    "- Headings: #, ##, ###\n",
    "- Paragraphs (plain text)\n",
    "- Bulleted lists using \"- \"\n",
    "- Numbered lists using \"1. \"\n",
    "- Blockquotes using \"> \"\n",
    "- Code blocks using triple backticks: ```language\n",
    "- Horizontal rules using \"---\"\n",
    "- Tables using \"|\" syntax with PLAIN TEXT CELLS ONLY\n",
    "\n",
    "ALLOWED INLINE SYNTAX:\n",
    "- **bold**\n",
    "- *italic*\n",
    "- `inline code`\n",
    "- [text](url)\n",
    "\n",
    "STRICTLY FORBIDDEN:\n",
    "- LaTeX or math notation (\\( \\), \\[ \\])\n",
    "- HTML\n",
    "- Unicode math symbols\n",
    "- Nested Markdown\n",
    "- Bold or italic inside tables\n",
    "- Heading levels deeper than ###\n",
    "\n",
    "If content cannot be expressed using the rules above,\n",
    "rewrite it as plain text instead.\n",
    "\n",
    "Follow these rules strictly.\n",
    "Message = {message}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "60f82a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    message: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d29e433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ__API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7931fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(state: State) -> State:\n",
    "    model = ChatGroq(model=\"openai/gpt-oss-120b\", api_key=GROQ__API_KEY)\n",
    "    prompt_value = prompt.invoke({\"message\": state[\"message\"]})\n",
    "    return {\"message\": model.invoke(prompt_value).content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a67a3c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2b13d38a510>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(State)\n",
    "graph.add_node(\"chat_node\", chat)\n",
    "graph.add_edge(START, \"chat_node\")\n",
    "graph.add_edge(\"chat_node\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70139980",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bbad178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"What is an LLM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d735a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "op = graph.invoke({\"message\": message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "454eea4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': '# Large Language Model (LLM)\\n\\nA **large language model** (LLM) is a type of artificial intelligence that has been trained on massive amounts of text data. It learns statistical patterns in language and can generate human‑like text, answer questions, translate languages, and perform many other language‑related tasks.\\n\\n## Core Concepts\\n\\n- **Training data** – billions of words from books, articles, websites, and other sources.  \\n- **Neural network architecture** – usually a transformer model that processes text in parallel.  \\n- **Parameters** – the adjustable weights of the network; modern LLMs have from hundreds of millions to trillions of parameters.  \\n- **Self‑supervised learning** – the model predicts missing words or next sentences without explicit labels.\\n\\n## How It Works\\n\\n1. **Tokenization** – input text is split into smaller units called tokens.  \\n2. **Embedding** – each token is converted into a numeric vector that captures its meaning.  \\n3. **Attention mechanism** – the model evaluates relationships between all tokens to understand context.  \\n4. **Prediction** – the model outputs probabilities for the next token, which are sampled to generate text.  \\n\\n## Common Uses\\n\\n- Drafting emails, reports, or code snippets.  \\n- Answering questions and providing explanations.  \\n- Translating between languages.  \\n- Summarizing long documents.  \\n- Assisting with tutoring or brainstorming ideas.\\n\\n---\\n\\n### Example Comparison Table\\n\\n| Feature                | Small Model | Large Model |\\n|------------------------|-------------|-------------|\\n| Parameter count        | < 10M       | > 100B      |\\n| Training data size     | < 1 GB      | > 1 TB      |\\n| Typical use cases      | Simple tasks| Complex, nuanced tasks |\\n| Response quality       | Basic       | High fidelity |\\n\\n---'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
